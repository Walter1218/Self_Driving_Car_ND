{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import batch_generate\n",
    "import tools\n",
    "import bbox_encode\n",
    "import bbox_decode\n",
    "from bbox import bbox_overlaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cls</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>File_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>790.01</td>\n",
       "      <td>184.59</td>\n",
       "      <td>1210.73</td>\n",
       "      <td>374.00</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1221</td>\n",
       "      <td>cyclist</td>\n",
       "      <td>113.04</td>\n",
       "      <td>166.59</td>\n",
       "      <td>291.61</td>\n",
       "      <td>374.00</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>54.64</td>\n",
       "      <td>200.99</td>\n",
       "      <td>321.79</td>\n",
       "      <td>344.57</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>661.86</td>\n",
       "      <td>164.18</td>\n",
       "      <td>813.92</td>\n",
       "      <td>274.49</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>229.61</td>\n",
       "      <td>184.82</td>\n",
       "      <td>388.04</td>\n",
       "      <td>274.36</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index      cls      x1      y1       x2      y2  \\\n",
       "0   1221      car  790.01  184.59  1210.73  374.00   \n",
       "1   1221  cyclist  113.04  166.59   291.61  374.00   \n",
       "2   1221      car   54.64  200.99   321.79  344.57   \n",
       "3   1221      car  661.86  164.18   813.92  274.49   \n",
       "4   1221      car  229.61  184.82   388.04  274.36   \n",
       "\n",
       "                             File_Path  \n",
       "0  ./KITTI/training/image_2/001221.png  \n",
       "1  ./KITTI/training/image_2/001221.png  \n",
       "2  ./KITTI/training/image_2/001221.png  \n",
       "3  ./KITTI/training/image_2/001221.png  \n",
       "4  ./KITTI/training/image_2/001221.png  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('kitti.csv')\n",
    "data = data.drop('Unnamed: 0', 1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>cls</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>File_Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>790.01</td>\n",
       "      <td>184.59</td>\n",
       "      <td>1210.73</td>\n",
       "      <td>374.00</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>54.64</td>\n",
       "      <td>200.99</td>\n",
       "      <td>321.79</td>\n",
       "      <td>344.57</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>661.86</td>\n",
       "      <td>164.18</td>\n",
       "      <td>813.92</td>\n",
       "      <td>274.49</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>229.61</td>\n",
       "      <td>184.82</td>\n",
       "      <td>388.04</td>\n",
       "      <td>274.36</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1221</td>\n",
       "      <td>car</td>\n",
       "      <td>589.70</td>\n",
       "      <td>174.77</td>\n",
       "      <td>653.16</td>\n",
       "      <td>221.56</td>\n",
       "      <td>./KITTI/training/image_2/001221.png</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  cls      x1      y1       x2      y2  \\\n",
       "0   1221  car  790.01  184.59  1210.73  374.00   \n",
       "1   1221  car   54.64  200.99   321.79  344.57   \n",
       "2   1221  car  661.86  164.18   813.92  274.49   \n",
       "3   1221  car  229.61  184.82   388.04  274.36   \n",
       "4   1221  car  589.70  174.77   653.16  221.56   \n",
       "\n",
       "                             File_Path  \n",
       "0  ./KITTI/training/image_2/001221.png  \n",
       "1  ./KITTI/training/image_2/001221.png  \n",
       "2  ./KITTI/training/image_2/001221.png  \n",
       "3  ./KITTI/training/image_2/001221.png  \n",
       "4  ./KITTI/training/image_2/001221.png  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_car = data[(data['cls']=='car')].reset_index()\n",
    "data_car = data_car.drop('level_0', 1)\n",
    "data_car.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gen = batch_generate.generate_train_anchor_batch(data_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./KITTI/training/image_2/003041.png\n"
     ]
    }
   ],
   "source": [
    "img, bbox = next(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras.objectives import categorical_crossentropy\n",
    "import cv2\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, merge, Convolution2D, MaxPooling2D, UpSampling2D,Lambda\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "_num_anchors = 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_rows = 640\n",
    "img_cols = 960"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Region Proposal Nets\n",
    "def vgg16():\n",
    "    inputs = Input((img_rows, img_cols,3))\n",
    "    inputs_norm = Lambda(lambda x: x/127.5 - 1.)\n",
    "    conv1 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name = 'conv1_1')(inputs)\n",
    "    conv1 = Convolution2D(64, 3, 3, activation='relu', border_mode='same', name = 'conv1_2')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "\n",
    "    conv2 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name = 'conv2_1')(pool1)\n",
    "    conv2 = Convolution2D(128, 3, 3, activation='relu', border_mode='same', name = 'conv2_2')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "\n",
    "    conv3 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name = 'conv3_1')(pool2)\n",
    "    conv3 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name = 'conv3_2')(conv3)\n",
    "    conv3 = Convolution2D(256, 3, 3, activation='relu', border_mode='same', name = 'conv3_3')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "\n",
    "    conv4 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name = 'conv4_1')(pool3)\n",
    "    conv4 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name = 'conv4_2')(conv4)\n",
    "    conv4 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name = 'conv4_4')(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    "\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name = 'conv5_1')(pool4)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name = 'conv5_2')(conv5)\n",
    "    conv5 = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name = 'conv5_3')(conv5)\n",
    "    \n",
    "    #Region Proposal Network\n",
    "    rpn = Convolution2D(512, 3, 3, activation='relu', border_mode='same', name='rpn_conv1')(conv5)\n",
    "    rpn_cls = Convolution2D(_num_anchors, 1, 1, activation='sigmoid', name='rpn_out_class')(rpn)\n",
    "    rpn_reg = Convolution2D(_num_anchors *4, 1, 1, activation='linear', name='rpn_out_regress')(rpn)\n",
    "\n",
    "    model = Model(input=inputs, output=[rpn_cls, rpn_reg])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#def loss\n",
    "lambda_rpn_regr = 1.0\n",
    "lambda_rpn_class = 1.0\n",
    "epsilon = 1e-4\n",
    "def rpn_loss_regr(num_anchors):\n",
    "    def rpn_loss_regr_fixed_num(y_true, y_pred):\n",
    "        x = y_true[:, :, :, 4 * num_anchors:] - y_pred\n",
    "        x_abs = K.abs(x)\n",
    "        x_bool = K.cast(tf.less_equal(x_abs, 1.0), tf.float32)\n",
    "\n",
    "        return lambda_rpn_regr * K.sum(y_true[:, :, :, :4 * num_anchors] \n",
    "                                       * (x_bool * (0.5 * x * x) + (1 - x_bool) \n",
    "                                       * (x_abs - 0.5))) / K.sum(epsilon + y_true[:, :, :, :4 * num_anchors]\n",
    "                                       )\n",
    "    return rpn_loss_regr_fixed_num\n",
    "\n",
    "\n",
    "def rpn_loss_cls(num_anchors):\n",
    "    def rpn_loss_cls_fixed_num(y_true, y_pred):\n",
    "        return lambda_rpn_class * K.sum(y_true[:, :, :, :num_anchors] * \n",
    "                                        K.binary_crossentropy(y_pred[:, :, :, :], y_true[:, :, :, num_anchors:])) / K.sum(epsilon + y_true[:, :, :, :num_anchors])\n",
    "    return rpn_loss_cls_fixed_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rpn = vgg16()\n",
    "rpn.load_weights('vgg16_weights_tf_dim_ordering_tf_kernels.h5', by_name=True)\n",
    "optimizer = Adam(lr=1e-4)\n",
    "rpn.compile(optimizer=optimizer, loss=[rpn_loss_cls(_num_anchors), rpn_loss_regr(_num_anchors)])\n",
    "gen = batch_generate.generate_train_anchor_batch(data_car)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./KITTI/training/image_2/005228.png\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: expected input_1 to have 4 dimensions, but got array with shape (640, 960, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-787664d47450>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#gen.next()#next(gen)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mloss_rpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mP_rpn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_rpn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/walter/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1313\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1314\u001b[0;31m             check_batch_axis=True)\n\u001b[0m\u001b[1;32m   1315\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muses_learning_phase\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_phase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/walter/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_batch_axis, batch_size)\u001b[0m\n\u001b[1;32m   1027\u001b[0m                                    \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m                                    \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1029\u001b[0;31m                                    exception_prefix='model input')\n\u001b[0m\u001b[1;32m   1030\u001b[0m         y = standardize_input_data(y, self.output_names,\n\u001b[1;32m   1031\u001b[0m                                    \u001b[0moutput_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/walter/.local/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    110\u001b[0m                                  \u001b[0;34m' to have '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                                  \u001b[0;34m' dimensions, but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                                  str(array.shape))\n\u001b[0m\u001b[1;32m    113\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_dim\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: expected input_1 to have 4 dimensions, but got array with shape (640, 960, 3)"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    x, y = next(gen)#gen.next()#next(gen)\n",
    "    loss_rpn = rpn.train_on_batch(x, y)\n",
    "    P_rpn = rpn.predict_on_batch(x)\n",
    "    print(loss_rpn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
